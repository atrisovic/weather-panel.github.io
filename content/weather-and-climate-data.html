
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Using Weather and Climate Data</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Developing a reduced-form specification" href="reduced-form-specification.html" />
    <link rel="prev" title="Introduction to the Tutorial" href="getting-started.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/climate_estimate_logo.png" class="logo" alt="logo">
  
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="getting-started.html">
   Introduction to the Tutorial
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Weather and Climate Data
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Using Weather and Climate Data
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Developing a reduced-form specification
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="reduced-form-specification.html">
   2. Developing a reduced-form specification
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Weighting schemes
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="weighting-schemes.html">
   3. Weighting schemes
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Geographical unit data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="geographical-unit-data.html">
   Generating geographical unit data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="working-with-shapefiles.html">
   Working with shapefiles
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Suggestions for work organization
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="suggestions.html">
   5. Suggestions when producing a panel dataset
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Contributors
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="contributors.html">
   Contributors
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/content/weather-and-climate-data.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/atrisovic/weather-panel.github.io/"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/atrisovic/weather-panel.github.io//issues/new?title=Issue%20on%20page%20%2Fcontent/weather-and-climate-data.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/atrisovic/weather-panel.github.io/edit/master/content/weather-and-climate-data.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-netcdf-data-format">
   1.1 The NetCDF Data Format
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#supported-languages">
     Supported Languages
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#netcdf-contents">
     netCDF Contents
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#netcdf-file-organization">
     netCDF File Organization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-netcdf-header">
     The netCDF Header
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attributes">
     Attributes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reading-netcdf-data">
     Reading netCDF data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#diagnostic-maps-of-climate-data">
     Diagnostic Maps of Climate Data
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#python-xarray">
       Python (xarray)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#matlab">
       Matlab
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gridded-data">
   1.2 Gridded Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#weather-data-products">
   1.3 Weather Data Products
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#observational-interpolated-datasets">
     “Observational” / Interpolated Datasets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reanalysis-datasets">
     Reanalysis Datasets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regional-datasets">
     Regional Datasets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#where-to-even-begin-resources-and-how-to-start-working-with-a-data-product">
   1.4 Where to Even Begin - Resources and How to Start Working with a Data Product
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#getting-started-with-a-data-product-sample-process-using-best-and-chirps">
     Getting Started with a Data Product - Sample Process using BEST and CHIRPS
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#getting-started-with-a-data-product-sample-process-using-era-5">
     Getting Started with a Data Product - Sample Process Using ERA-5
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#thinking-ahead-to-climate-projections">
     Thinking ahead to climate projections
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-quick-summarizing-note">
     A Quick Summarizing Note
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-warning-on-hydrological-variables-precipitation-humidity-etc">
   1.5 A Warning on Hydrological Variables (Precipitation, Humidity, etc.)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-final-note-on-station-data">
   1.6 A Final Note on Station Data
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="using-weather-and-climate-data">
<h1>1. Using Weather and Climate Data<a class="headerlink" href="#using-weather-and-climate-data" title="Permalink to this headline">¶</a></h1>
<p>When using weather data as independent variables in an economic model, or climate data to project your research results into the future, please note:</p>
<ul class="simple">
<li><p>There is no universally <em>right</em> or <em>correct</em> weather or climate data product</p></li>
<li><p>Every weather or climate data product has its use cases, limitations, uncertainties, and quirks</p></li>
</ul>
<p>This section will introduce you to the right questions to ask when deciding on climate or weather data to use in your research.</p>
<div class="section" id="the-netcdf-data-format">
<h2>1.1 The NetCDF Data Format<a class="headerlink" href="#the-netcdf-data-format" title="Permalink to this headline">¶</a></h2>
<p>Almost all climate and weather datasets are released in <a class="reference external" href="https://climatedataguide.ucar.edu/climate-data-tools-and-analysis/netcdf-overview">netCDF</a> format. It’s efficient, self-describing, and supported by any major programming language, though you’ll have to pre-process data into another format (.csv, etc.) before you can use it in STATA. If you get familiar with the commands to read the header and access data in the language you’re most comfortable with, you will be able to work with almost any climate or weather dataset published in the world.</p>
<div class="section" id="supported-languages">
<h3>Supported Languages<a class="headerlink" href="#supported-languages" title="Permalink to this headline">¶</a></h3>
<p>Through this section, when possible relevant commands for working with netCDF files are listed for:</p>
<ul class="simple">
<li><p>Matlab (native support)</p></li>
<li><p>python</p>
<ul>
<li><p><a class="reference external" href="http://xarray.pydata.org/en/stable/">xarray</a> (recommended) - a package for dealing with N-dimensional data that natively supports netCDF files</p></li>
<li><p><a class="reference external" href="https://unidata.github.io/netcdf4-python/netCDF4/index.html">netCDF4-python</a> module</p></li>
</ul>
</li>
<li><p>R (<a class="reference external" href="https://cran.r-project.org/web/packages/ncdf4/index.html">ncdf4</a> package)</p></li>
<li><p><a class="reference external" href="http://nco.sourceforge.net">nco</a> (“netCDF operators”) - command line tools</p>
<ul>
<li><p>documentation may look overwhelming, but at its core, it’s an easy way to check the contents of a file, collate different netCDF files, and extract individual variables without having to go through a full language.</p></li>
<li><p>important commands: <code class="docutils literal notranslate"><span class="pre">ncview</span></code> (to display spatial data), <code class="docutils literal notranslate"><span class="pre">ncks</span></code> (“nc kitchen sink” - to split or
concatenate files command line), and <code class="docutils literal notranslate"><span class="pre">ncdump</span></code> (to print contents of the file)</p></li>
</ul>
</li>
</ul>
<p>For any R code chunks, it’s assumed the ncdf4 package is loaded (<code class="docutils literal notranslate"><span class="pre">library(ncdf4)</span></code>). For any python code chunks, it’s assumed that the xarray package is loaded as <code class="docutils literal notranslate"><span class="pre">xr</span></code> (<code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">xarray</span> <span class="pre">as</span> <span class="pre">xr</span></code>) or the netCDF4-python module is loaded as <code class="docutils literal notranslate"><span class="pre">nc</span></code> (<code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">netCDF4</span> <span class="pre">as</span> <span class="pre">nc</span></code>).</p>
<p>NB: If you know several of the languages referred to in this tutorial and just want the author’s opinion on which one to use, I would suggest:</p>
<ul class="simple">
<li><p>Matlab: if you like a simple, bare-bones treatment of data where you are in explicit control of everything that happens, at the expense of having to be more careful with the background / file processing work</p></li>
<li><p>python + <code class="docutils literal notranslate"><span class="pre">xarray</span></code>: if you want tools specifically designed for modern uses of weather/climate data that do much of the annoying background work (dealing with different file structures, variable names, date formats, etc.) for you, at the expense of less flexbility for uncommon needs</p></li>
</ul>
</div>
<div class="section" id="netcdf-contents">
<h3>netCDF Contents<a class="headerlink" href="#netcdf-contents" title="Permalink to this headline">¶</a></h3>
<p>The core function of NetCDF files is to store matrices. These matrices may have one dimension (e.g., a vector of years), two dimensions (e.g., elevation across space), three dimensions (e.g., weather varying across space and time), or more. The other contents of the file help you to interpret these matrices.</p>
<p>NetCDF files have three kinds of information:</p>
<ul class="simple">
<li><p><em>Attribute</em>: Documentation information, associated to either individual variables or the file as a whole. Each attribute has a name (e.g., <code class="docutils literal notranslate"><span class="pre">version</span></code>) and text content (e.g., “Someone to Lean On”).</p></li>
<li><p><em>Variables</em>: The matrices themselves, containing the data you want.. Each matrix has an order of dimensions. For a two-dimensional matrix, the first dimension corresponds to the rows and the second dimension to the columns.</p></li>
<li><p><em>Dimensions</em>: The dimensions information in a NetCDF says how many entries are in each dimension. For example, a file containing a 1-degree grid over the world would typically lave a <code class="docutils literal notranslate"><span class="pre">lon</span></code> dimension of length 360 and a <code class="docutils literal notranslate"><span class="pre">lat</span></code> dimension with length 180.</p></li>
</ul>
<p>Typically, there will be variables that correspond to each of the dimensions, and sometimes these will have the same name as the dimension objects. These variables give you the value of each index in the dimension. For example, if there is a <code class="docutils literal notranslate"><span class="pre">lon</span></code> dimension with length 360, there will usually be a <code class="docutils literal notranslate"><span class="pre">lon</span></code> or <code class="docutils literal notranslate"><span class="pre">longitude</span></code> variable, which is a matrix with the single <code class="docutils literal notranslate"><span class="pre">lon</span></code> dimension, and its contents would look something like <code class="docutils literal notranslate"><span class="pre">[-179.5,</span> <span class="pre">-178.5,</span> <span class="pre">-177.5,</span> <span class="pre">...,</span> <span class="pre">179.5]</span></code>.</p>
</div>
<div class="section" id="netcdf-file-organization">
<h3>netCDF File Organization<a class="headerlink" href="#netcdf-file-organization" title="Permalink to this headline">¶</a></h3>
<p>The netCDF file structure is self-describing, meaning all the information you need to understand what data are within are contained within the file as well (in theory). <em>However</em>, the format doesn’t require any information be put there, so names of attributes, which attributes are included, etc., may vary between files, especially if they’re ‘unofficial’ files not created by a major modeling group as part of a larger project.</p>
<p>But fear not: thankfully, most data you will be facing has standardized to something akin to the format used by CMIP output (a ‘model intercomparison project’ in which different modeling groups agreed to run their models on identical climate ‘experiments’ and publish their data in a uniform format; CMIP6 is the latest generation of the largest ‘MIP’, analysis of which makes up a substantial portion of IPCC reports).</p>
<p>For example, climate data you will encounter will generally follow a CMIP5 filename format, of the form:</p>
<p><code class="docutils literal notranslate"><span class="pre">[variable</span> <span class="pre">shorthand]_[frequency]_[model</span> <span class="pre">name]_[experiment]_[run]_[timeframe].nc</span></code></p>
<p>or a CMIP6 filename format, of the form:</p>
<p><code class="docutils literal notranslate"><span class="pre">[variable</span> <span class="pre">shorthand]_[frequency]_[model</span> <span class="pre">name]_[experiment]_[run]_[grid</span> <span class="pre">label]_[timeframe].nc</span></code></p>
<p>(This terminology will also be useful to recognize even when filenames are not of this format, as is likely for weather data products.)</p>
<ul class="simple">
<li><p>most commonly encountered <strong>variable shorthands:</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">tas</span></code> = temperature; “[air] temperature at surface,” which is different from “surface temperature” (the temperature of the ground) or temperature at other heights. Sometimes also listed as <code class="docutils literal notranslate"><span class="pre">t2m</span></code> for 2m air temperature or <code class="docutils literal notranslate"><span class="pre">TREFHT</span></code> for reference height temperature. (Always assumed to be taken a few feet off the ground to minimize confusing air temperature with excess heat released by the ground)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pr</span></code> = precipitation rate</p></li>
</ul>
</li>
<li><p><strong>frequency</strong>: <em>day</em> for daily, <em>ann</em> for annual. <em>mon</em> for monthly; is sometimes listed as <em>Amon</em> for atmospheric variables; feel free to ignore this distinction.</p></li>
<li><p><strong>experiment</strong>: some descriptor of the forcing used (forcing = profile of greenhouse gases), e.g. <em>rcp85</em> for the RCP8.5 scenario frequently used in projections.</p></li>
<li><p><strong>run</strong>: if the same model was run multiple times with the same forcing, but different physics or initial conditions, it will be noted here (e.g. <em>r1i1p1</em>). Don’t worry about this.</p></li>
<li><p><strong>grid label</strong>: whether data was regridded from the model’s native grid</p></li>
<li><p><strong>timeframe</strong>: frequently in <code class="docutils literal notranslate"><span class="pre">yyyymmdd-yyyymmdd</span></code> format.</p></li>
</ul>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>For more information on “CMIP5” and “CMIP6” terminology, please see: <a class="reference external" href="https://pcmdi.llnl.gov/CMIP6/Guide/dataUsers.html">CMIP6 Guidance for Data Users</a> or the <a class="reference external" href="https://pcmdi.llnl.gov/mips/cmip5/requirements.html">CMIP5 Standard Output</a>.</p>
</div>
<p>There are two common ways in which data is stored in netCDF files:</p>
<ul class="simple">
<li><p>variables: each file contains a single variable over the whole (or a large chunk) of the time domain</p></li>
<li><p>time slices: each file contains a single timestep with a suite of variables</p></li>
<li><p>combination: file contains many variables over a large time domain (rare due to size constraints)</p></li>
</ul>
<p>To figure out which file saving convention your netCDF file uses, and what is contained, you can check the header of the file:</p>
</div>
<div class="section" id="the-netcdf-header">
<h3>The netCDF Header<a class="headerlink" href="#the-netcdf-header" title="Permalink to this headline">¶</a></h3>
<p>netCDF files are self-describing, meaning that they contain information about the data contained within. Every netCDF file has a header that describes these contents. This will often be the first aspect of the file you look at, to verify the file has the variables you need, in what order the dimensions of the variables are stored, etc. Here are the commands to print the header for netCDF filename <code class="docutils literal notranslate"><span class="pre">fn</span></code>, for each mentioned tool above:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>nco</p></th>
<th class="head"><p>Matlab</p></th>
<th class="head"><p>R</p></th>
<th class="head"><p>python (netCDF4)</p></th>
<th class="head"><p>python (xarray)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">ncdump</span> <span class="pre">-h</span> <span class="pre">fn</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ncdisp(fn)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ncfile</span> <span class="pre">&lt;-</span> <span class="pre">nc_open(fn)</span></code><br><code class="docutils literal notranslate"><span class="pre">ncfile</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ds</span> <span class="pre">=</span> <span class="pre">nc.Dataset(fn))</span></code><br><code class="docutils literal notranslate"><span class="pre">ds</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ds</span> <span class="pre">=</span> <span class="pre">xr.open_dataset(fn))</span></code><br><code class="docutils literal notranslate"><span class="pre">ds</span></code></p></td>
</tr>
</tbody>
</table>
<p>The header will open with ‘global attributes,’ which are just text fields that primarily tell you housekeeping information (modeling groups, copyright information, etc.). Then, for each variable contained within the file, the header will tell you what dimensions they contain and their respective sizes, plus variable-specific attributes, like units.</p>
<p>Use the header to check what the variable you want is called, and what dimensions it has. For a variable-focused netCDF file (see above), the dimensions will likely be <code class="docutils literal notranslate"><span class="pre">lon,lat,time</span></code> (though always verify - some will save their data with the <code class="docutils literal notranslate"><span class="pre">time</span></code> variable first and non-gridded data may be saved as <code class="docutils literal notranslate"><span class="pre">location,time</span></code>). The file will also contain populated variables for each of these dimensions, giving the values of <code class="docutils literal notranslate"><span class="pre">lon,lat,time</span></code>  at each point (be aware - for non-rectangular grids, the <em>variables</em> <code class="docutils literal notranslate"><span class="pre">lon</span></code> and <code class="docutils literal notranslate"><span class="pre">lat</span></code> may each be 2-D arrays as well). If you are using <code class="docutils literal notranslate"><span class="pre">xarray</span></code> in python, <code class="docutils literal notranslate"><span class="pre">xr.open_dataset()</span></code> will usually be able to tell which dimensions are time, lon, lat without any additional specification.</p>
</div>
<div class="section" id="attributes">
<h3>Attributes<a class="headerlink" href="#attributes" title="Permalink to this headline">¶</a></h3>
<p>Here are some important common “attributes” of netCDF files or variables:</p>
<ul class="simple">
<li><p><strong>Calendar</strong> - probably the most important and inconsistent attribute for climate data (for historical ‘weather’ data products, one would hope it just follows the Gregorian calendar). Either global, or attached to the “record-keeping dimension” (<code class="docutils literal notranslate"><span class="pre">time</span></code> ). Common formats include</p>
<ul>
<li><p><em>365_day</em> / <em>noleap</em> / <em>365day</em> / <em>no_leap</em> / etc. - the years are magically shortened so they all have 365 days (most common for climate data)</p></li>
<li><p><em>gregorian</em> / <em>proleptic_gregorian</em> - modern calendar with leap years</p></li>
<li><p><em>360_day</em> - rare calendar in which the year has 360 days (so all months have equal lengths). To my knowledge, the Hadley Model is the only major recent model to use this, but be aware of its existence.</p></li>
</ul>
</li>
<li><p><strong>Units</strong> - generally attached to the variable in question. Common variable units:</p>
<ul>
<li><p><em>Temperature</em> - almost always in Kelvin</p></li>
<li><p><em>Precipitation</em> - often in <em>kg/m^2s</em>, which is the SI unit for precipitation rate (volume per time). Multiply by 3600 to get mm/hour, or 141.7323 to get in/hour (the density of water is 1000 kg/m^3, multiplying by the density calculates the rate in m/s, or depth/time - the rest is just accounting to your desired units of depth and time).</p></li>
</ul>
</li>
<li><p><strong>Missing / Fill Value</strong> - if there are some crazy high or low values in your data, you may want to check if those just represent the missing / fill value, a common sub-attribute of variables. Data may also be stored in <a class="reference external" href="https://currents.soest.hawaii.edu/ocn_data_analysis/_static/masked_arrays.html">“masked arrays”</a>.</p></li>
</ul>
</div>
<div class="section" id="reading-netcdf-data">
<h3>Reading netCDF data<a class="headerlink" href="#reading-netcdf-data" title="Permalink to this headline">¶</a></h3>
<p>netCDF files can be easily imported as numeric data in any language. Here are some common ways:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Matlab</p></th>
<th class="head"><p>R</p></th>
<th class="head"><p>python (netCDF4)</p></th>
<th class="head"><p>python (xarray)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">ncread(fn,var);</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ncfile</span> <span class="pre">&lt;-</span> <span class="pre">nc_open(fn)</span></code><br><code class="docutils literal notranslate"><span class="pre">var</span> <span class="pre">&lt;-</span> <span class="pre">ncvar_get(ncfile,var)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ncf</span> <span class="pre">=</span> <span class="pre">nc.Dataset(fn)</span></code> <br><code class="docutils literal notranslate"><span class="pre">ncf.variables[var][:]</span></code><br>(<code class="docutils literal notranslate"><span class="pre">ncf.variables[var]</span></code> will return a <code class="docutils literal notranslate"><span class="pre">float</span></code> object that keeps the attributes from the netCDF file)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ds</span> <span class="pre">=</span> <span class="pre">xr.open_dataset(fn))</span></code><br>ds.var<br>(data is loaded lazily and only fully loaded when calculations are done - to force loading, run <code class="docutils literal notranslate"><span class="pre">ds.load()</span></code>)</p></td>
</tr>
</tbody>
</table>
<p>You’ll often only want or need a subset of a variable. In this case, make sure you know in what order the dimensions of the variable are saved at (see above; unless you are working with <code class="docutils literal notranslate"><span class="pre">xarray</span></code>, which handles this for you. Check the docs.). Say, if you want only a 5 x 5 x 365 subset of the data, you’d use:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Matlab</p></th>
<th class="head"><p>R</p></th>
<th class="head"><p>python (xarray)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">ncread(fn,var,</span></code><br><code class="docutils literal notranslate"><span class="pre">[1</span> <span class="pre">1</span> <span class="pre">1],[5</span> <span class="pre">5</span> <span class="pre">365]);</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ncfile</span> <span class="pre">&lt;-</span> <span class="pre">nc_open(fn)</span></code><br><code class="docutils literal notranslate"><span class="pre">vardata</span> <span class="pre">&lt;-</span> <span class="pre">ncvar_get(ncfile,var,</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">start=c(1,1,1),</span> <span class="pre">count=c(5,5,365))</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ds</span> <span class="pre">=</span> <span class="pre">xr.open_dataset(fn))</span></code><br><code class="docutils literal notranslate"><span class="pre">ds.loc[0:5,0:5,0:365]</span></code> <br>(data is loaded lazily and only fully loaded when calculations are done, so you can slice data without loading it into memory. Slicing can be done by time, variable, etc.; check the docs)</p></td>
</tr>
</tbody>
</table>
<p>As mentioned above, these files also include populated variables that give values for indices along each dimension (<code class="docutils literal notranslate"><span class="pre">lon,</span> <span class="pre">lat</span></code> / <code class="docutils literal notranslate"><span class="pre">location</span></code> and <code class="docutils literal notranslate"><span class="pre">time</span></code>), which can be extracted like any other variable using the functions listed above. Make sure to double-check the name of those dimensions in the netCDF header first (the author has seen grid variables listed for example as <code class="docutils literal notranslate"><span class="pre">lat</span></code>, <code class="docutils literal notranslate"><span class="pre">latitude</span></code>, <code class="docutils literal notranslate"><span class="pre">Latitude</span></code>, <code class="docutils literal notranslate"><span class="pre">Lat</span></code>, <code class="docutils literal notranslate"><span class="pre">latitude_1</span></code>, <code class="docutils literal notranslate"><span class="pre">nav_lat</span></code>, and any number of other names). As mentioned, <code class="docutils literal notranslate"><span class="pre">xarray</span></code> has built-in methods for identifying the dimensions in the file, regardless of order.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">time</span></code> variable can also be listed in a few different formats. An integer representation of “days since [some date, often 1850-01-01]” is common, as is an integer representation of the form [YYYYMMDD], among others. The key is to always check the description of the variable in the header, and adjust your methods accordingly until it’s in a format you want it in. If you’re using python, the <code class="docutils literal notranslate"><span class="pre">xarray</span></code> package has the ability to interpret some of these time representations for you and translates them into the <code class="docutils literal notranslate"><span class="pre">datetime64</span></code> class, which makes some kinds of manipulation, like averaging over months, easier.</p>
</div>
<div class="section" id="diagnostic-maps-of-climate-data">
<h3>Diagnostic Maps of Climate Data<a class="headerlink" href="#diagnostic-maps-of-climate-data" title="Permalink to this headline">¶</a></h3>
<p>You may want to visualize your weather or climate data, either for internal diagnostics or for production figures showing your data. It’s generally good practice to double-check that your data downloaded and processed correctly, by making sure there aren’t suspiciously many NAs/NaNs, that the lat/lon grid matches up with where the data should go (first-order check: does your temperature/precipitation field trace out major land/ocean boundaries, etc.), and that the data is consistent. Here are easy ways to plot the first timestep of a gridded dataset:</p>
<div class="section" id="python-xarray">
<h4>Python (xarray)<a class="headerlink" href="#python-xarray" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Assuming your variable is a 3-D (lat,lon,time, in any order) </span>
<span class="c1"># variable called &quot;tas&quot;, in a dataset loaded using </span>
<span class="c1"># ds = xr.open_dataset() as above. This will get you a </span>
<span class="c1"># &quot;QuadMesh&quot; image - just a heatmap of your data:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">tas</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="c1"># (for the time mean, you can use ds.tas.mean(time).plot() </span>
<span class="c1"># similarly)</span>
    
<span class="c1"># Example with gegographic information:</span>
<span class="kn">import</span> <span class="nn">cartopy.crs</span> <span class="k">as</span> <span class="nn">ccrs</span> <span class="c1"># If plotting on a geographically correct map    </span>
<span class="c1"># (see resources below on why transforms/projections </span>
<span class="c1"># need to be explicitly noted)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="n">ccrs</span><span class="o">.</span><span class="n">EckertIV</span><span class="p">()</span>
<span class="n">ds</span><span class="o">.</span><span class="n">tas</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
 <span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="n">ccrs</span><span class="o">.</span><span class="n">PlateCarree</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">coastlines</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>For more information on plotting geographic data with xarray and cartopy, the author highly recommends the <a class="reference external" href="https://earth-env-data-science.github.io/intro.html">“Earth and Environmental Science” with python guide</a>, especially the section on <a class="reference external" href="https://earth-env-data-science.github.io/lectures/mapping_cartopy.html%5D">“Making Maps with Cartopy”</a></p>
</div>
</div>
<div class="section" id="matlab">
<h4>Matlab<a class="headerlink" href="#matlab" title="Permalink to this headline">¶</a></h4>
<div class="highlight-Matlab notranslate"><div class="highlight"><pre><span></span><span class="c">% Assuming your dataset is called &quot;tas&quot; (lon,lat,time)</span>
<span class="c">% This will just plot a heatmap of your data:</span>
<span class="n">pcolor</span><span class="p">(</span><span class="nb">squeeze</span><span class="p">(</span><span class="n">tas</span><span class="p">(:,:,</span><span class="mi">1</span><span class="p">)).</span><span class="o">&#39;</span><span class="p">);</span> <span class="n">shading</span> <span class="s">flat</span>

<span class="c">% Alternatively, with geographic information:</span>
<span class="n">axesm</span><span class="p">()</span> <span class="c">% Set desired projection in the function call; i.e. &#39;eckert4&#39;</span>
<span class="n">pcolorm</span><span class="p">(</span><span class="n">lat</span><span class="p">,</span><span class="n">lon</span><span class="p">,</span><span class="nb">squeeze</span><span class="p">(</span><span class="n">tas</span><span class="p">(:,:,</span><span class="mi">1</span><span class="p">)).</span><span class="o">&#39;</span><span class="p">);</span> <span class="n">shading</span> <span class="s">flat</span> 
<span class="c">% coast.mat is included with Matlab installations; this will add </span>
<span class="c">% coastlines. </span>
<span class="n">coasts</span><span class="p">=</span><span class="n">matfile</span><span class="p">(</span><span class="s">&#39;coast.mat&#39;</span><span class="p">)</span>
<span class="n">geoshow</span><span class="p">(</span><span class="n">coasts</span><span class="p">.</span><span class="n">lat</span><span class="p">,</span><span class="n">coasts</span><span class="p">.</span><span class="n">long</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="gridded-data">
<h2>1.2 Gridded Data<a class="headerlink" href="#gridded-data" title="Permalink to this headline">¶</a></h2>
<p>Weather data is traditionally collected at weather stations. Weather stations are imperfect, unevenly distributed point sources of data whose raw output may not be suitable for economic and policy applications. Weather stations are more likely to be located in wealthier and more populated areas, which makes them less useful for work in developing countries or for non-human variables such as agriculture. Their number and coverage constantly changes, making it difficult to weigh or to compare across regions. Despite being the most accurate tool for measuring the current weather at their location, they may hide microclimates nearby.</p>
<p>Thankfully, a large suite of data products have been developed to mitigate these issues. These generally consist of combining or ‘assimilating’ many data sources and analysis method into a ‘gridded dataset’ - the earth is divided into a latitude x longitude (x height) grid, and one value for a variable (temperature, precipitation, etc.) is provided at each gridpoint and timestep. These data products generally cover either the whole globe or all land areas, and provide consistent coverage at each grid point location. <em>(NB: Some variables, especially relating to hydrology, may be better suited to station data, by providing single values for large regions such as river basins)</em>.</p>
<p>However, since the world is not made up of grids (i.e. the world is not broken up into 50 x 50 km chunks, within which all weather conditions are identical), some processing has to be done even for historical “weather” data, and other limitations arise. For historical data, this processing is one of the sources of differences between data products, and for climate data, the simulation of sub-grid processes is the greatest source of uncertainty between models.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Keep in mind that just because a dataset exists at a certain resolution, does not mean it is accurate at that resolution!</p>
</div>
<p>The next section will briefly introduce how these products are generated, how to choose between them, and best practices for using “historical” data.</p>
</div>
<div class="section" id="weather-data-products">
<h2>1.3 Weather Data Products<a class="headerlink" href="#weather-data-products" title="Permalink to this headline">¶</a></h2>
<p><strong>The Interpolation - Reanalysis Spectrum</strong>
Historical data products differ by how they <a class="reference external" href="https://climatedataguide.ucar.edu/climate-data/atmospheric-reanalysis-overview-comparison-tables">“assimilate”</a> (join observational with model data) or combine data, and how much “additional” information is added beyond (pre-processed) station data. They can be thought of as a rough spectrum ranging from ‘observational’ data products that merely statistically interpolate data into a grid to ‘reanalysis’ products that feed data products into a sort of climate model to produce a more complete set of variables. Some datasets are observational but include topographic and other physical information in their statistical methods, while some reanalysis datasets use pure model output for only some variables.</p>
<p>Both ends of their spectrum have tradeoffs, and generalizable statements about these tradeoffs are hard to make because of differences in methodologies. The following are a few simplified rules of thumb:</p>
<div class="section" id="observational-interpolated-datasets">
<h3>“Observational” / Interpolated Datasets<a class="headerlink" href="#observational-interpolated-datasets" title="Permalink to this headline">¶</a></h3>
<p>Examples: GISTEMP, GHCN, Wilmot and Matsuura (aka “UDel”), Berkeley Earth (aka “BEST”), HadCrut4, PRISM, CHIRPS, etc.</p>
<ul class="simple">
<li><p>Observations are statistically interpolated into a grid with little or no physical information added (though topography and - less commonly - wind speed are occasionally included)</p></li>
<li><p>Products generally differ by which stations or other data sources are included and excluded</p></li>
</ul>
<p><em>Strengths</em>:</p>
<ul class="simple">
<li><p>Simple, biases well-understood</p></li>
<li><p>High correlation with source station data in areas with strong station coverage</p></li>
</ul>
<p><em>Weaknesses</em>:</p>
<ul class="simple">
<li><p>Less realistic outside areas with strong station coverage</p></li>
<li><p>Statistical interpolation means data not bound by physicality</p></li>
<li><p>Often only available at lower temporal resolution (e.g. monthly)</p></li>
</ul>
<p>(see also UCAR’s Model Data Guide <a class="reference external" href="https://climatedataguide.ucar.edu/climate-data/global-temperature-data-sets-overview-comparison-table">summary</a> on temperature datasets)</p>
</div>
<div class="section" id="reanalysis-datasets">
<h3>Reanalysis Datasets<a class="headerlink" href="#reanalysis-datasets" title="Permalink to this headline">¶</a></h3>
<p>Examples: ERA-INTERIM, ERA-5, JRA-55, MERRA-2, NCEP2 (outdated), etc.</p>
<ul class="simple">
<li><p>Observational data are combined with climate models to produce a full set of atmospheric variables</p></li>
<li><p>Products differ by what data is included (as with interpolated
datasets), but now also differ by which underlying models are used</p></li>
</ul>
<p><em>Strengths</em>:</p>
<ul class="simple">
<li><p>Large extant literature on most major reanalysis products; limitations are generally well-understood (though not always well-estimated; and biases are often tested against interpolated datasets)</p></li>
<li><p>Coverage in areas with low station coverage (generally poorer or less populated areas) is more physically reasonable</p></li>
<li><p>Covers a large number of variables (though uncertainties differ between them)</p></li>
</ul>
<p><em>Weaknesses</em>:</p>
<ul class="simple">
<li><p>Not fully physical either - laws of conservation e.g. are often relaxed</p></li>
<li><p>Limited by often significant biases in underlying models that may or may not be well understood</p></li>
<li><p>Accuracy in areas of high station density may be lower than in interpolated products</p></li>
</ul>
<p>(see also UCAR’s Model Data Guide <a class="reference external" href="https://climatedataguide.ucar.edu/climate-data/atmospheric-reanalysis-overview-comparison-tables">summary</a> on reanalyses)</p>
</div>
<div class="section" id="regional-datasets">
<h3>Regional Datasets<a class="headerlink" href="#regional-datasets" title="Permalink to this headline">¶</a></h3>
<p>Observational datasets exist with both global coverage (e.g. GISTEMP, HadCRUT, etc.) or regional coverage (e.g. PRISM in North America, TRMM in the tropics, etc.). Global datasets attempt to build a self-consistent database spanning the whole globe, and are therefore more likely to have sparser data coverage in specific regions - both as a logistical limitation, but also to ensure data pre-proceessing is as standardized as possible. Regional datasets may provide higher-resolution coverage and more specialized methodologies by incorporating local climatological knowledge or data sources that are not publicly available or parsable by global datasets (see e.g. the discussion in <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/B9780128159989000075">Dinku et al. 2019</a>).</p>
</div>
</div>
<div class="section" id="where-to-even-begin-resources-and-how-to-start-working-with-a-data-product">
<h2>1.4 Where to Even Begin - Resources and How to Start Working with a Data Product<a class="headerlink" href="#where-to-even-begin-resources-and-how-to-start-working-with-a-data-product" title="Permalink to this headline">¶</a></h2>
<p>Some incredibly useful resources to keep in mind while working with weather data are the following two sites:</p>
<ul class="simple">
<li><p>https://climatedataguide.ucar.edu - an encyclopedia for weather and climate data products with expert guidance on strengths and weaknesses for most commonly-used datasets</p></li>
<li><p>https://reanalyses.org - a forum and wiki for makers and users of reanalyses with a focus on evaluating data products and comparing them with observational data</p></li>
<li><p>https://www.esrl.noaa.gov/psd/data/writ/moncomp/datasets/ - a “who’s who” of historical weather products with basic facts about each</p></li>
</ul>
<p>These resources will help you determine which data product is right for you (and better interpret results from existing studies - for example, NCEP2, which was commonly used in economics and policy studies, has known issues including larger biases in the Southern Hemisphere).</p>
<p>Additionally, think about if you want climatological (“what you expect”) data, rather than weather (“what you get”) data. Climatology is generally known with more precision and available at higher resolution, but will only represent average patterns (e.g., average temperature by month) rather than any particular year.</p>
<div class="section" id="getting-started-with-a-data-product-sample-process-using-best-and-chirps">
<h3>Getting Started with a Data Product - Sample Process using BEST and CHIRPS<a class="headerlink" href="#getting-started-with-a-data-product-sample-process-using-best-and-chirps" title="Permalink to this headline">¶</a></h3>
<p>Say you’re looking at agriculture in Ethiopia. You would like both temperature and precipitation data (see warning on hydrological variables below), and would like to use observational datasets. You consider BEST for temperature due to their daily output and CHIRPS, a hybrid station-satellite data product, for precipitation because you found literature specifically examining its biases in your region of interest.</p>
<ol class="simple">
<li><p><em>Understand the Data Product</em> - you look up CHIRPS and UDel on the UCAR Climate Data Guide</p>
<ol class="simple">
<li><p>CHIRPS is unfortunately not covered on the UCAR Climate Data Guide. <em>However</em>, you find several articles specifically validating it in Ethiopia (e.g. <a class="reference external" href="https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.3244">Dinku et al. 2018</a> or <a class="reference external" href="https://eprints.soton.ac.uk/435188/">Gebrechorkos et al. 2018</a>). You see that satellite data products are more biased South of the Rift Valley than North. You also see that CHIRPS tends to overestimate rainfall. You consider how these biases may affect your results.</p></li>
<li><p>BEST <em>is</em> <a class="reference external" href="https://climatedataguide.ucar.edu/climate-data/global-surface-temperatures-best-berkeley-earth-surface-temperatures">covered</a> on the Climate Data Guide. You see that it is able to provide high-resolution data because it includes more incomplete and partial station records than other global products. However, you also see that the data is highly smoothed, meaning that it will likely be more biased in areas with large heterogeneity in temperature - for example in the mountainous highlands of Ethiopia. You resolve to use different sources to check for robustness.</p></li>
</ol>
</li>
<li><p><em>Prepare to Download the Data</em> - most weather products will require some bureaucracy to download data, and most have their own weird quirks about how they want data to be downloaded. CHIRPS and BEST do not require bureaucracy (creating accounts, signing data agreements, etc.), but CHIRPS will require some scripting to download.</p>
<ol class="simple">
<li><p>CHIRPS: After some searching, you find that CHIRPS data is stored in a publicly accessible <a class="reference external" href="https://data.chc.ucsb.edu/products/CHIRPS-2.0/">directory</a> (this is a simpler setup than most). You navigate to the <code class="docutils literal notranslate"><span class="pre">africa_daily/bils/</span></code> directory, and choose between 0.5 degree resolution and 2.5 degree resolution. However, you realize that you may have to write a shell script to download this data, to avoid clicking every file separately (using <code class="docutils literal notranslate"><span class="pre">ftplib</span></code> in python and similar packages is also an option).</p></li>
<li><p>BEST: you click on ‘Get Data (external)’ on the Climate Data Guide website, taking you to Berkley Earth’s data overview page. You navigate down to the section on ‘Gridded Data’. You’ll have to click on every decade separately, but without further ado, clean NetCDF files are being downloaded to your machine.</p></li>
</ol>
</li>
<li><p><em>Accessing the Data</em></p>
<ol class="simple">
<li><p>CHIRPS: Unfortauntely, the data is not in <code class="docutils literal notranslate"><span class="pre">.nc</span></code> format, but in <code class="docutils literal notranslate"><span class="pre">bil</span></code> format. This is a raster data format - but thankfully, this is easy enough to deal with in the featured languages - for example, <code class="docutils literal notranslate"><span class="pre">xarray</span></code> has <code class="docutils literal notranslate"><span class="pre">xr.open_rasterio()</span></code>, MATLAB has <code class="docutils literal notranslate"><span class="pre">multibandread</span></code>, and <code class="docutils literal notranslate"><span class="pre">R</span></code> has the <code class="docutils literal notranslate"><span class="pre">raster</span></code> package. The author would suggest you resave the file as a NetCDF, for consistency and ease of access (using <code class="docutils literal notranslate"><span class="pre">xr.to_netcdf</span></code>, for example).</p></li>
<li><p>BEST: the filename, as is typical for observational datasets, is in tis own format - so you might want to rename them into CMIP format just for ease of reading. By reading the NetCDF header, you note that the grid variables are stored as <code class="docutils literal notranslate"><span class="pre">latitude</span></code> and <code class="docutils literal notranslate"><span class="pre">longitude</span></code> and the temperature as <code class="docutils literal notranslate"><span class="pre">temperature</span></code>, and you’re set to go!</p></li>
</ol>
</li>
</ol>
<p>These datasets are stored in different geographical grids and will need to be regridded to a common grid, using tools like <code class="docutils literal notranslate"><span class="pre">xesmf</span></code> in python. See also Section 3 on weigthing schemes.</p>
</div>
<div class="section" id="getting-started-with-a-data-product-sample-process-using-era-5">
<h3>Getting Started with a Data Product - Sample Process Using ERA-5<a class="headerlink" href="#getting-started-with-a-data-product-sample-process-using-era-5" title="Permalink to this headline">¶</a></h3>
<p>Say you’re studying heat waves in the Sahel. Weather station data is low, so you need a gridded data product. You consider ERA5, the most advanced modern reanalysis data product as of 2019, recently released by the European Centre for Medium-Range Weather Forecasting (ECMWF, which incidentally also produces the world’s most respected hurricane forecast model).</p>
<ol class="simple">
<li><p><em>Understand the Data Product</em> - you look up ERA5 on the UCAR Climate Data Guide https://climatedataguide.ucar.edu/climate-data/era5-atmospheric-reanalysis;</p>
<ol class="simple">
<li><p>It tells you the product has a resolution of about 31 km horizontally (this is about as high as it gets in this generation of data products) and includes 137 pressure levels (this is the vertical resolution; you can safely ignore this if you just care about temperature by the surface). It also allows hourly data (this too is uncommon; most only provide daily, or maybe 3-hourly). However, observe caution here: just because the data is available at this resolution does not mean it is reliable at that resolution, and you will likely need to spend time aggregating the data across time to develop your final dataset.</p></li>
<li><p>You see that it even gives you an estimate of the internal model uncertainty by rerunning the same analysis 10 times (10 “ensemble members”), though in “weaknesses” you note that the uncertainty may be underestimated.</p></li>
<li><p>It extends back to 1979 for now (1979 is a common cutoff point due to the start of satellite observations in 1978).</p></li>
<li><p>The summary describes it as an ‘extraordinary product’, so you feel good in your choice, especially since most of the weaknesses described (temperature in the tropopause, upper stratosphere global average temperature, etc.) don’t seem to affect your region or variables of interest (near-surface temperature).</p></li>
</ol>
</li>
<li><p><em>Prepare to Download the Data</em> - most weather products will require some bureaucracy to download data, and most have their own weird quirks about how they want data to be downloaded</p>
<ol class="simple">
<li><p>You click on ‘Get Data (external)’ in the Data Guide to find a <a class="reference external" href="https://cds.climate.copernicus.eu/#%21/search?text=ERA5&amp;type=dataset">link</a> to the Copernicus climate data store. There, you realize that you’ll need to sign up for an account (modern data products from larger institutions such as the ECMWF will thankfully have an automated system for this; some smaller products may require you to wait until someone manually approves your account), which just asks you to sign a data use agreement (remember to correctly cite data sources!).</p></li>
<li><p>The download page also gives you some documentation for the data product, including variable names - you see “2m air temperature” in Kelvin is the variable you need.</p></li>
<li><p>You click on the data you want, which years you want it for, etc., and prepare to check out. Here, there are two options: GRIB, and NetCDF (experimental). You click NetCDF, because after this guide, you feel comfortable working with it (*NB: GRIB is another meteorological data format - it’s less common and less flexible than NetCDF, but slightly more efficient in storage. The author has yet to see it as the only option for a data product; NetCDF is still dominant. GRIB files can be converted easily to NetCDF files through <a class="reference external" href="https://confluence.ecmwf.int/display/OIFS/How+to+convert+GRIB+to+netCDF">command-line tools</a> such as <a class="reference external" href="https://code.zmaw.de/projects/cdo">cdo</a> *).</p></li>
<li><p>You click download, and voila! (<em>NB: Many datasets, especially those from smaller institutions, will not give up their secrets so easily. Be prepared to have to deal with “wget” scripts, “jblob” scripts, writing ftp scripts, and so forth, with well-meaning but poorly-written accompanying documentation. In some of these cases, it might be fastest to call up your best climate researcher friend, who may be able to just copy their scripts to you</em>).</p></li>
</ol>
</li>
<li><p><em>Accessing the Data</em></p>
<ol class="simple">
<li><p>However, you see an issue - your climate data is named some weird automatically generated filename. In this case, you may want to rename the file following the CMIP5 convention introduced above, or, if there are multiple files, write a script to do this for you (pro tip: the information in a netCDF header, which will tell you the timespan and variables of each file, is always extractable; using e.g. <code class="docutils literal notranslate"><span class="pre">ncinfo</span></code> in Matlab, or the object generated by <code class="docutils literal notranslate"><span class="pre">nc_open</span></code> in R. If you’re using <code class="docutils literal notranslate"><span class="pre">xarray</span></code>, <code class="docutils literal notranslate"><span class="pre">xr.open_mfdataset()</span></code> will let you list multiple files, which it will sort correctly into one dataset automatically if all goes well.) (<em>NB: this is uncommon but not unheard of for weather products. Be prepared to deal with inconsistent and weird filenames)</em></p></li>
<li><p>Reading off the netCDF header (as detailed above) shows that your variable is named <code class="docutils literal notranslate"><span class="pre">t2m</span></code> (stored as a <code class="docutils literal notranslate"><span class="pre">longitude</span> <span class="pre">x</span> <span class="pre">latitude</span> <span class="pre">x</span> <span class="pre">time</span></code> grid), the grid variables are called <code class="docutils literal notranslate"><span class="pre">latitude</span></code>  and <code class="docutils literal notranslate"><span class="pre">longitude</span></code>, and the time variable is called <code class="docutils literal notranslate"><span class="pre">time</span></code>. Now you can access the data as detailed above!</p></li>
</ol>
</li>
</ol>
</div>
<div class="section" id="thinking-ahead-to-climate-projections">
<h3>Thinking ahead to climate projections<a class="headerlink" href="#thinking-ahead-to-climate-projections" title="Permalink to this headline">¶</a></h3>
<p>Research linking social outcomes to weather variations often aim to project results into the future to estimate the impact of climate change on their variable of interest. We have chosen (at least for now) not to expand this guide to include information on climate projection because of its immense complexity. Oftentimes a more sophisticated understanding of how models work and their uncertainties is needed to avoid underestimating propagated uncertainties in your final estimates. As with weather data products (potentially even more so), there is no <em>right</em> or <em>correct</em> climate model, or group of models to use (see e.g. <a class="reference external" href="https://link.springer.com/article/10.1007/s10584-010-9800-2">Knutti 2010</a> or <a class="reference external" href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2017GL073370">Collins 2017</a>). Emissions scenarios, the response of the models to emissions scenarios, intermodel variability, and <em>intra</em>-model variability all add to the uncertainty in your projection, and their relative strength may depend on the timescale and aims of your study.</p>
<p>However, to get started in thinking about incorporating changes in climate into your analysis, the author also recommends:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/wcc.579">Nissan et al. (2019)</a>: “On the use and misuse of climate change projections in international development”</p></li>
<li><p><a class="reference external" href="https://academic.oup.com/reep/article-abstract/7/2/181/1522753">Auffhammer et al. (2013)</a>: “Using Weather Data and Climate Model Output in Economic Analyses of Climate Change”</p></li>
</ul>
<p>If you plan to project results into the future, you can start thinking about its logistics now. Climate data comes from imperfect models whose raw output generally has to be “bias-corrected” before being used in econometric or policy research contexts. Bias-correction involves using information from a weather dataset to inform the output of a climate model, either by applying model changes to the weather data (so-called “delta-method” projection) or by adjusting the model output by applying a historical difference between the model and weather data to the future model output. We won’t go into details about these methods (like everything in this field, they have their strengths and weaknesses), but you should generally use data that has been bias-corrected to the same weather data set you are using to inform your econometric model. Oftentimes this bias-correction is still conducted by the econometric or policy-focused research group, but some pre-bias-corrected climate projections exist. For example, NASA’s <a class="reference external" href="https://nex.nasa.gov/nex/projects/1356/">(NEX-GDDP)</a> dataset is bias-corrected to the <a class="reference external" href="http://hydrology.princeton.edu/data.pgf.php">Global Meteorological Forcing Dataset (GMFD) for Land Surface Modeling</a> historical dataset.</p>
</div>
<div class="section" id="a-quick-summarizing-note">
<h3>A Quick Summarizing Note<a class="headerlink" href="#a-quick-summarizing-note" title="Permalink to this headline">¶</a></h3>
<p>This process may seem overwhelming, especially given the large variety of data products that exist, and the sometimes rather opaque processes for figuring out what works best.</p>
<p>The author’s personal suggestion is to start off with a regional observational dataset, if one exists for the region and variables you wish to examine, or else a well-understood global observational dataset. Don’t use a dataset or a data assimilation methodology just because previous work (even big-name papers) have used them. There are enough examples in the literature of problematic uses of weather and climate data (for examples of discussions about these issues see e.g. <a class="reference external" href="https://www.aeaweb.org/articles?id=10.1257/aer.102.7.3749">Fisher et al. 2012</a>, <a class="reference external" href="https://www.mitpressjournals.org/doi/abs/10.1162/REST_a_00478">Burke et al. 2015</a>, etc.).</p>
<p>Furthermore, check your results with multiple datasets from the latest generation! Consider performing your analysis with a purely station-based dataset and one that includes satellite data; or compare results to those from a reanalysis dataset if you are worried about statistical interpolation in your region of interest. This may not make a huge difference for more stable variables in areas with high station coverage (e.g. temperature in North America), but could be a useful robustness check for more problematic ones (e.g. precipitation). If the choice of ‘historical’ dataset changes your results, think about how their biases may interact with your analysis to figure out what’s causing the discrepancy.</p>
</div>
</div>
<div class="section" id="a-warning-on-hydrological-variables-precipitation-humidity-etc">
<h2>1.5 A Warning on Hydrological Variables (Precipitation, Humidity, etc.)<a class="headerlink" href="#a-warning-on-hydrological-variables-precipitation-humidity-etc" title="Permalink to this headline">¶</a></h2>
<p><img alt="Hi, I'm your new meteorologist and a former software developer. Hey, when we say 12pm, does that mean the hour from 12pm to 1pm, or the hour centered on 12pm? Or is it a snapshot at 12:00 exactly? Because our 24-hour forecast has midnight at both ends, and I'm worried we have an off-by-one error." src="https://imgs.xkcd.com/comics/meteorologist.png" />
<em>As usual, <a class="reference external" href="https://imgs.xkcd.com/comics/meteorologist.png">XKCD</a> gets it best</em></p>
<p>Precipitation is a special beast. It is spatiotemporally highly heterogeneous (it can rain a lot in one place, and not rain at all on the other side of the hill, or an hour or a minute later) and difficult to measure accurately, but is frequently desired for socioeconomic applications.</p>
<p><img alt="Data from Bosliovich et al. (2015); gridded data products disagree on average global monthly precipitation by up to 40%, and aren't always consistent!" src="../_images/global_monthly.png" />
<em>Data from <a class="reference external" href="https://gmao.gsfc.nasa.gov/pubs/docs/Bosilovich785.pdf">Bosilovich et al. (2015)</a>; gridded data products disagree on average global monthly precipitation by up to 40%, and aren’t always consistent!</em></p>
<p>Unlike temperature, which is relatively uniform spatiotemporally and can be interpolated with a relatively high degree of confidence, precipitation data is very difficult to interpolate and requires a much more complex understanding of regional precipitation patterns to assimilate into gridded products. Consequently, gridded precipitation data should be used with <a class="reference external" href="https://climatedataguide.ucar.edu/climate-data/atmospheric-reanalysis-overview-comparison-tables">“extreme caution”</a>, and its uncertainties should not be underestimated.</p>
<p>Even ‘raw’ precipitation data from weather stations and rain gauges are problematic. Developing a reliable, easily scaled rain gauge network is a difficult task. For example, a common type of rain gauge, the ‘tipping bucket’, only records rain in discrete intervals (when the bucket fills and subsequently ‘tips’), and therefore could record a rainstorm if a drizzle tips an already-full bucket. A meteorologist once told the author of this section that tipping buckets stationed in remote areas may be stuck in the ‘tipped’ position for some time before anyone notices or can repair them.</p>
<p>In general, rain gauges of most types are biased low. In strong wind conditions, many drops may not enter the rain catch in a gauge due to turbulence; in strong storms, point estimates may miss areas of greatest intensity. Rain data averaged over areas with complex terrain is biased because of the vertical profile of precipitation (stations are generally in valleys). Kenji Matsuura (of the UDel dataset fame) in his <a class="reference external" href="https://climatedataguide.ucar.edu/climate-data/global-land-precipitation-and-temperature-willmott-matsuura-university-delaware">expert guidance</a> on his dataset explains: “Under-catch bias can be nontrivial and very difficult to estimate adequately, especially over extensive areas…”</p>
<p>Bias-correcting is integrated into weather data products, often involving assimilation of multiple data sources (satellites, radar, etc.) but significant biases remain (see above Figure).</p>
<p>Precipitation is often recommended as a control in economic models, but its unique character makes it difficult to work with. Beyond the strong uncertainty in precipitation data, precipitation is highly non-gaussian and its correlation with temperature is time- and space- dependent. When using precipitation in your model, be aware of its limitations, check robustness against multiple data products, or on geographic subsets that have better station coverage and potentially less biased data. Make sure to read studies evaluating your chosen data product - for example <a class="reference external" href="https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.3244">Dinku et al. 2018</a> for CHIRPS in Eastern Africa (a useful Google Scholar search for any product could be “[data product name] validation OR evaluation OR bias OR uncertainty”). Finally, make sure you think about what role precipitation plays in your model - see <a class="reference external" href="#2.1.-Choosing-weather-variables">2.1. Choosing weather variables</a>!</p>
</div>
<div class="section" id="a-final-note-on-station-data">
<h2>1.6 A Final Note on Station Data<a class="headerlink" href="#a-final-note-on-station-data" title="Permalink to this headline">¶</a></h2>
<p>Station data (e.g. <a class="reference external" href="https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-ghcn">Global Historical Climatology Network (GHCN)</a> and the Global Summary of the Day) <em>can</em> be useful in policy and economic applications, and has been frequently used by especially older studies in the field. It provides a high degree of accuracy in areas of high station density, which generally corresponds to areas with a higher population density and a higher income level. Especially if you are working with urban areas, station data will likely capture the urban heat island effect more accurately than any gridded product.</p>
<p>However, station data can’t be seen as the ‘true’ weather either; assumptions and calibration methodologies affect data here as well (see e.g. <a class="reference external" href="https://journals.ametsoc.org/doi/full/10.1175/BAMS-D-14-00226.1">Parker 2015</a>), some variables remain rather uncertain, and the influence of microclimates even in close proximity to stations shouldn’t be underestimated (think for example the Greater Los Angeles region, where temperature can vary up to 35 F between the inland valleys and the coast).</p>
<p>Finally, under normal circumstances, <strong>don’t try to interpolate data yourself</strong>. Interpolated and reanalysis data products covered above were specifically designed for this purpose, and have vetted methodologies and publicly available citable diagnostics and uncertainties.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="getting-started.html" title="previous page">Introduction to the Tutorial</a>
    <a class='right-next' id="next-link" href="reduced-form-specification.html" title="next page">2. Developing a reduced-form specification</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>