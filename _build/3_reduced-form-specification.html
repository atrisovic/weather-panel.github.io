---
redirect_from:
  - "/3-reduced-form-specification"
title: |-
  Developing a reduced-form specification
prev_page:
  url: /2_using-weather-and-climate-data.html
  title: |-
    Using Weather and Climate Data
next_page:
  url: /4_weighting-schemes.html
  title: |-
    Weighting schemes
suffix: .md

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="3.-Developing-a-reduced-form-specification:">3. Developing a reduced-form specification:<a class="anchor-link" href="#3.-Developing-a-reduced-form-specification:"> </a></h1><p>This section describes some of the considerations that go into
developing a reduced-form specification using weather panel data.</p>
<p>For an extensive review of the results available from the climate
econometric literature and the empirical methods used to identify
them, a good resource is
<a href="http://science.sciencemag.org/content/353/6304/aad9837">Social and Economic Impacts of Climate</a>.</p>
<h2 id="Choosing-weather-variables">Choosing weather variables<a class="anchor-link" href="#Choosing-weather-variables"> </a></h2><p>The choice of weather variables depends on the question we are trying
to answer, and there are many forms to represent any given
variable. For example, in the case of temperature, we can use
$T_{avg}$, $T_{min}$, $T_{max}$, days above 30 C, heating and cooling
degree-days, or growing degree-days. A few of the important weather variables are listed below:</p>
<ul>
<li><p>Temperature</p>
<ol>
<li><em>$T_{min}$, $T_{max}$:</em>  Many socioeconomic processes are more
sensitive to extreme temperatures than to variation in the
average. This is also useful when temperature variation is
large, leading to significant differences in cold end and hot
end response. These are important metric when heterogeneity
between each time unit matters, and capture heat waves and cold
spells. Also, note that $T_{min}$ reflects nighttime
temperatures while $T_{max}$ is reached in the daytime.</li>
<li><em>$T_{avg}$:</em>  A good mean metric for seeing average response
over the temperature support, when there is not much variation
in temperature across time unit considered in the
study. $T_{avg}$ is most appropriate when there is some natural
inertia in the response, so that the dependent variable is
responding to a kind of average over the last 24 hours. Note
that $T_{avg}$ is often just $(T_{min} + T_{max}) / 2$, unless
calculated from sub-daily data.</li>
<li><em>HDD/CDD &amp; GDD:</em>  Degree days (DD) are a measure of ’how much’
and for ’how long’ the outside air temperature was above or
below a certain level.  Reference:
<a href="https://www.degreedays.net/introduction">https://www.degreedays.net/introduction</a></li>
</ol>
</li>
<li><p>Precipitation
  As described above, precipitation is highly local, poorly
  measured, and poorly predicted.</p>
<ol>
<li><em>Total precipitation (e.g., over a year)</em>: Often used as a
control, but not a very good reflection of the relevance of
precipitation ot a socioeconomic process.</li>
<li><em>Soil water, potential evapotranspiration rate (PET), Palmer
drought severity index (PDSI), and water runoff/availability</em>:
These are more appropriate for representing water stress.</li>
<li><p><em>Number of of rainy/dry days, or moments of the precipitation
distribution</em>: Distribution of precipitation often matters more
than total.</p>
<p>Precipitation is an important control to include, even if it’s not
the main variable of interest, since temperature and precipitation
are correlated. However, we should remember that the properties of
precipitation and temperature variables are very different in the
way they affect humans. For example, binning of annual temperature
variable, keeping high temperature bins small-sized, can explain
variation in death rates due to heat waves events. However, if we
want to see the variation in death rates due to storm events,
using binned annual precipitation is likely not going to give us
the variation in death rates, rather we would have to separately
account for storm events by using an additional control</p>
</li>
</ol>
</li>
<li><p>River discharge rate
  River flows are generally measured at the station-level. While
  runoff is avaialble in gridded products, it is not a good
  reflection of water availability. Hydrological models (like VIC)
  can translate precipitation into river discharges across a region.</p>
</li>
<li><p>Wind speed
  The process of interest determines how wind speeds should be
  measured. For example, normal speeds are important for
  agriculture, squared speeds for distructive force, and cubic
  speeds for wind turbine power. Also consider gust velocity, which
  is generally available.</p>
</li>
<li><p>Evapotranspiration rate
  [Define; relate to water stress and ag. productivity?]</p>
</li>
<li><p>Solar radiation
  [Longwave vs. shortwave, and uses]</p>
</li>
<li><p>Humidity
  [Also describe wetbulb temperature.]</p>
</li>
<li><p>Ocean temperature
  [Do you mean SST?]</p>
</li>
<li><p>Atmospheric CO2
  [Haven't seen this. Maybe drop it?]</p>
</li>
<li><p>Storm events
  [Break it down: wind, precip., storm surge, and note warning systems.]</p>
</li>
<li><p>Sea level
  [Not sure if this is useful for panel regressions.]</p>
</li>
<li><p>Ocean currents
  [Few uses of this.]</p>
</li>
<li><p>Soil erosion and salinity
  [Salinity is only available staticly, right? Erosion: would this
  be from a model?]</p>
</li>
<li><p>Plant productivity
  [Maybe describe NPP?]</p>
</li>
</ul>
<h2 id="Common-functional-forms-(pros,-cons,-and-methods)">Common functional forms (pros, cons, and methods)<a class="anchor-link" href="#Common-functional-forms-(pros,-cons,-and-methods)"> </a></h2><p>Different functional forms serve different purposes. First, think
about the "true model" that relates your dependent variable to your
weather variables, and then try to turn it into a linear expression
that you can estimate.</p>
<p>Some of the frequently used functional forms along with a good
reference for understanding them in detail are listed below.</p>
<ul>
<li><p>Bins</p>
<ol>
<li>Assignment of observations to bins. e.g.  15C-20C, 20C-25C, ...  for temperature</li>
<li>Uses the mean metric, so its advantage is non-parametric nature</li>
<li>Highly susceptible to existence of outliers in data</li>
</ol>
</li>
</ul>
<p><a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/app.3.4.152">https://pubs.aeaweb.org/doi/pdfplus/10.1257/app.3.4.152</a></p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Polynomial_regression">Polynomial</a><ol>
<li>Fitting an n-degree polynomial function for weather variables</li>
<li>More poly degrees provide better data fitting</li>
<li>Smooth curve nature doesn’t highlight important irregularities in data</li>
</ol>
</li>
</ul>
<ul>
<li>Restricted Cubic Spline<ol>
<li>Fitting a piecewise polynomial function between pre-specified knots</li>
<li>More independence compared to poly in choosing function knots</li>
<li>Highly parametric due to freedom of choice of knots</li>
</ol>
</li>
</ul>
<p><a href="https://support.sas.com/resources/papers/proceedings16/5621-2016.pdf">https://support.sas.com/resources/papers/proceedings16/5621-2016.pdf</a></p>
<ul>
<li>Linear Spline<ol>
<li>Fitting a line between cutoff values e.g.  25C CDD/0C HDD for temp</li>
<li>Less parametric and very useful for predicting mid-range response</li>
<li>Linear and highly sensitive to choice of cutoff values</li>
</ol>
</li>
</ul>
<p><a href="http://people.stat.sfu.ca/~cschwarz/Consulting/Trinity/Phase2/TrinityWorkshop/Workshop-handouts/TW-04-Intro-splines.pdf">http://people.stat.sfu.ca/~cschwarz/Consulting/Trinity/Phase2/TrinityWorkshop/Workshop-handouts/TW-04-Intro-splines.pdf</a></p>
<h2 id="Cross-validation">Cross-validation<a class="anchor-link" href="#Cross-validation"> </a></h2><p>Cross-validation can be done to check the <em>internal validity</em>
and the <em>external validity</em> of the model estimates. For checking
internal validity, the model can be fit to a subset of the dataset,
and evaluated on the remainder. For example, you can leave particular
regions out of your regression or remove a random <em>1/k</em> of your data
(k-fold cross validation) instead of running a full-sample
regression.</p>
<p>For gauging external validity, model is run on some new dataset that
has not been not used in the model-evaluation process. For example, by
predicting the response for a new country using global regression model
estimates, and comparing it to the actual observations.</p>
<p>Although cross-validation is not universally performed by researchers,
and many people continue to rely on the measure of R-squared
statistic. However, we know from our basic statistics learning, how
badly this it can perform even in very simple cases. Cross-validation
can be an effective approach for doing model-selection.</p>
<p>[Can you give a couple examples-- e.g., cross-validation to determine
the number of poly terms, or the thresholds for GDDs?]</p>
<h2 id="Fixed-Effects-Regression">Fixed Effects Regression<a class="anchor-link" href="#Fixed-Effects-Regression"> </a></h2><h2 id="Dealing-with-the-spatial-and-temporal-scales-of-economic-processes">Dealing with the spatial and temporal scales of economic processes<a class="anchor-link" href="#Dealing-with-the-spatial-and-temporal-scales-of-economic-processes"> </a></h2><p>Weather data products are generally available in <em>gridded</em> form,
developed through careful interpolation and/or reanalysis. The grids
used can vary in size across datasets, but they can be aggregated to
administrative units like county, city, etc., using appropriate
weighted aggregation methods. Think about the scale of your
administrative units, relative to the scale of the grid cells. If the
regions are much bigger than the grid cells, a weighted average across
included cells is appropriate. If the regions are much smaller than
the cells, it will probably be necessary to aggregate the regions,
since the level of variation is only at the grid cell level. If the
two are of similar sizes, it is generally necessary to account for the
amount that each grid cell lies within each region. This can be
calculated as a transformation matrix, with a row for each region and
a column for each cell. Once the matrix is calculated, it can be
reused for each time step.</p>
<p>Typically, preparing the weather variables requires some kind of
non-linear transformation. For example, estimating a polynomial
functional form requires raising the temperatures to various
powers. The square of a weighted average of grid-level temperatures is
not the same as the weighted average of the square of grid-level
temperatures.</p>
<p>While doing the spatial aggregation, we need to decide whether we want
to transform the data first and then aggregate it
(transformation-before-aggregation) or aggregate it and then transform
it (aggregation-before-transformation). This decision is based on the whether the phenomenon
in consideration is occurring at the local (grid) scale or at the
larger administrative units (country, state, county, etc.)
scale. Also, it matters what variable is in consideration. For
example, doing aggregation-before-transformation for temperature will
distort the signal less that doing it for precipitation. This is because
precipitation is highly local both temporally and spatially; it could
rain for &lt;1 min in &lt;1 km radius area. Let us try to understand these
two methods using counties as our higher administrative level:</p>
<p><strong>Transformation-before-aggregation</strong></p>
<p>When an economic process is occurring at the grid level (for example,
for individuals or households), we need to first do our estimation at
the grid level. For example, to estimate the effect of temperature on
human mortality at the county level, we should reckon that the effect
of temperature on mortality is a local phenomenon, so the estimation
should happen at the lowest possible level.</p>
<p>Here, we need to do the required transformation of our
weather variables at the grid level, then aggregate these values using
a weighted averaging method, and feed these into our estimation
procedure.</p>
<h3 id="Mathematical-formulation-for-transformation-before-aggregation-method">Mathematical formulation for transformation-before-aggregation method<a class="anchor-link" href="#Mathematical-formulation-for-transformation-before-aggregation-method"> </a></h3><p>We want to understand how local agents respond to weather
shocks. Suppose that there exists an agent-level dose-response curve,
$y_{js} = f(T_{ps})$, for a socioeconomic outcome for agent $j$, where
the temperature affecting agents is in grid cell $p$ and occurs in
timestep $s$ (e.g., if the agents respond on a day-by-day basis,
$T_{ps}$ is the local weather for a single day).</p>
<p>However, we do not observed agent-level responses. Instead, we have
region-wide sums, $y_{it}$ for region $i$ and reporting period
$t$. For example, if $y_{js}$ is death risk for agent $j$ for a given
day, we may only observe total deaths across a region in each year, $y_{it} =
\sum_{\text{s in year t}} \sum_{\text{j in region i}} y_{js}$.</p>
<p>We can determine the agent-level response $f(T_{ps})$ if we assume
linearity. First, let us represent this the way we would if we could
run a regression with agent-level data, breaking up the dose-response
curve into a sum of terms:
$$f(T_{ps}) = \beta_1 g_1(T_{ps}) + \beta_2 g_2(T_{ps}) + \cdots + \beta_k g_k(T_{ps})$$
where $g_k(T_{ps})$ is a transformation of the weather
variables. For example, for a cubic response curve, $g_1(T_{ps}) = T_{ps}$,
$g_2(T_{ps}) = T_{ps}^2$, and $g_3(T_{ps}) = T_{ps}^3$.</p>
<p>We know that
$$y_i = \sum_{\text{js in it}} y_{js} = \sum_{\text{js in it}}
\beta_1 g_1(T_{ps}) + \beta_2 g_2(T_{ps}) + \cdots + \beta_k
g_k(T_{ps})$$</p>
<p>We can rearrange this to:
$$y_i = \beta_1 (\sum_{\text{sj in it}} g_1(T_{ps})) + \beta_2
(\sum_{\text{sj in it}} g_2(T_{ps})) + \cdots + \beta_k
(\sum_{\text{sj in it}} g_k(T_{ps}))$$</p>
<p>Or, more simply, $$y_i = \beta<em>1 N</em>{it} g<em>1(T</em>{ps}) + \beta<em>2
N</em>{it} g<em>2(T</em>{ps}) + \cdots + \beta<em>k N</em>{it} g<em>k(T</em>{ps})</p>
<p>where $N_{it}$ is the number of agent-timestep observations
represented included within region $i$ and reporting period $t$.</p>
<p>[Azhar, I've left your text below. I'm not sure if you want to keep
it, or move it elsewhere.]</p>
<p>Consider a grid $\theta$ located in county $i$ with $T_{\theta it}$ as its temperature at time $t$. We want to generate an aggregate temperature transformation, $f(T_{it}^k)$, for county $i$ at time $t$, after aggregating over the grids $\theta \in \Theta$, where $\Theta$ denotes the set of grids that are located inside county $i$.</p>
<p>Here, $k\in\{1,2,...,K\}$ denotes the $k^{th}$ term of transformation. For example, in case of $K$-degree polynomial transformation, it will be $K$ polynomial terms, and in case of $K$-bins transformation, it will be $K$ temperature bins. So, we can write:</p>
$$f(T_{it}^k)=g(T_{\theta it})$$<p>where, $g(.)$ denotes the transformation mapping on the grid-level temperature data.</p>
<p>Once we have $f(T_{it}^k)$ for each  $k\in\{1,2,...,K\}$, we can use them to generate the full nonlinear transformation $F(T_{it})$, associating $\beta^k$ parameter with $k^{th}$ term of transformation. We have:</p>
$$F(T_{it})=\sum_{k\in \{1,2,...,K\}} \beta^k*f(T_{it}^k)$$<p>The coefficients, $\beta^k \,\forall k\in \{1,2,...,K\}$ are estimated using an appropriate estimation technique for generating the response functions.</p>
<p>Suppose we want a model for estimating the effect of temperature on human mortality $Y_{it}$.</p>
$$Y_{it}=\sum_{k\in \{1,2,...,K\}} \beta^k*T_{it}^k + \alpha_i + \zeta_t + \varepsilon_{it}$$<p>We can run a fixed effects estimation on the county-level data for estimating the coefficients, and then generate the response functions for different counties in our data. As pointed out in the cross-validation section, it is important to check for internal validity and the external validity after the estimation is over.</p>
<p><strong>Bin</strong></p>
<p>Consider doing a 6-bins bin transformation of temperature variable. Let us take equal sized bins for simplicity, but in actual binning procedure, we might want to have smaller sized bins around the temperature values where we expect most of the response to occur. For now, the $K=6$ temp bins are: $&lt;-5^\circ C$, $-5^\circ C-5^\circ C$, $5^\circ C-15^\circ C$, $15^\circ C-25^\circ C$, $25^\circ C-35^\circ C$ and $&gt;35^\circ C$.
As defined earlier, the grid $\theta$ temperature is $T_{\theta i t}$. For transformation, we will have to map actual temperature observations to the respective bins that we have defined above. Then, take the weighted average of these terms across all the grids that come under a specific county. The mapping is defined as follows:</p>
$$f(T_{it}^k)=\sum_{\theta \in \Theta} \psi_{\theta} \sum \mathbf{1} \left \{  {T_{\theta i t} \in k} \right \}$$<p>$$\forall k \in \{1,2,...,6\}$$</p>
<p>where $\psi_{\theta}$ is the weight assigned to the $\theta$ grid. The aggregate transformation is as below:</p>
$$F(T_{it})=\sum_{k\in \{1,2,...,6\}} \beta^k*f(T_{it}^k)$$<h4 id="Polynomial">Polynomial<a class="anchor-link" href="#Polynomial"> </a></h4><p>Consider doing a 4-degree polynomial transformation of temperature variable. We need to first generate the remaining polynomial terms, namely $T_{\theta i t}^2$, $T_{\theta i t}^3$ and $T_{\theta i t}^4$, by raising original $T_{\theta i t}$ to powers 2, 3 and 4 respectively. Then, take the weighted average of these terms across all the grids that come under a county. So, we have:</p>
$$f(T_{it}^k)=\sum_{\theta \in \Theta} \psi_{\theta}*T_{\theta i t}^k$$<p>$$\forall k \in \{1,2,3,4\}$$</p>
<p>where $\psi_{\theta}$ is the weight assigned to the $\theta$ grid. The aggregate transformation is as below:</p>
$$F(T_{it})=\sum_{k\in \{1,2,3,4\}} \beta^k*f(T_{it}^k)$$<h4 id="Restricted-Cubic-Spline">Restricted Cubic Spline<a class="anchor-link" href="#Restricted-Cubic-Spline"> </a></h4><p>For transforming the temperature data into restricted cubic splines, we need to fix the location and the number of knots. The reference above on cubic splines can be helpful in deciding the knot specifications. As before let the grid $\theta$ temperature be $T_{\theta i t}$. Let us do this exercise for $n$ knots, placed at $t_1&lt;t_2&lt;...&lt;t_n$, then for $T_{\theta i t}$, which is a continuous variable, we have a set of $(n-2)$ new variables. We have:</p>
$$f(T_{i t}^k)= \sum_{\theta \in \Theta} \psi_{\theta}*\{(T_{\theta i t}-t_k)^3_+ - (T_{\theta i t} - t_{n-1})^3_+*\frac{t_n-t_k}{t_n-t_{n-1}}+(T_{\theta i t} - t_{n})^3_+*\frac{t_{n-1}-t_k}{t_{n}-t_{n-1}}\}$$<p>$$\forall k \in \{1,2,...,n-2\}$$</p>
<p>where, $\psi_{\theta}$ is the weight assigned to the $\theta$ grid.</p>
<p>And, each spline term in the parentheses $(\nabla)^3_+$ e.g. $(T_{\theta i t} - t_{n-1})^3_+$ is called a truncated polynomial of degree 3, which is defined as follows:</p>
<p>$\nabla^3_+=\nabla^3_+$ if $\nabla^3_+&gt;0$</p>
<p>$\nabla^3_+=0$ if $\nabla^3_+&lt;0$</p>
<p>The aggregate transformation is as below:</p>
$$F(T_{it})=\sum_{k\in \{1,2,...,n-2\}} \beta^k*f(T_{it}^k)$$<h4 id="Linear-Spline">Linear Spline<a class="anchor-link" href="#Linear-Spline"> </a></h4><p>Linear spline is a special kind of spline function, which has two knots, and the segment between these two knots is a linear function. It is also called ‘restricted’ linear spline, since the segments outside the knots are also linear. To implement this, we first decide location of the two knots, say $t_1&lt;t_2$. Then, closely following the cubic spline method, we get:</p>
$$f(T_{it}^1)=\sum_{\theta \in \Theta} \psi_{\theta}*(T_{\theta i t}-t_2)_+$$$$f(T_{it}^2)=-\sum_{\theta \in \Theta} \psi_{\theta}*(T_{\theta i t}-t_1)_+$$<p>where, $\psi_{\theta}$ is the weight assigned to the $\theta$ grid.</p>
<p>And, each spline term in the parentheses $(\nabla)_+$ e.g. $(T_{\theta i t} - t_2)_+$ is called a truncated polynomial of degree 1, which is defined as follows:</p>
<p>$\nabla_+=\nabla_+$ if $\nabla_+&gt;0$</p>
<p>$\nabla_+=0$ if $\nabla_+&lt;0$</p>
<p>The aggregate transformation is as below:</p>
$$F(T_{it})=\sum_{k\in \{1,2\}} \beta^k*f(T_{it}^k)$$<p><strong>Aggregation-before-transformation</strong></p>
<p>When an economic process is occurring at the county level, we need to first do the weather variable aggregation at the county level. We do the weather variable transformation after we have aggregated it to the county level using weighted averaging method, and then run our estimation on the county level data. For example, to estimate the effect of storm events on public service employment at the administrative block level, we need to take into account the fact that hiring/firing of public service employees happens at the block level only.  Estimating grid-level effects will lead to wrong estimation, as it would result in zero estimate for those (almost all) grid cells which do not have the block office coordinates, and extremely large values for those (very few) cells, which comprise of the block office coordinates. The mathematical formulation for aggregation-before-transformation can be learned through transformation-before-aggregation formulation described above, with a change that the aggregation step precedes the transformation step.</p>
<p>Weather data products can have temporal resolution finer than scale of daily observations. Like spatial aggregation, we can do temporal aggregation to month, year, or decade; however, unlike spatial aggregation, the averaging process is standard in all general cases.</p>

</div>
</div>
</div>
</div>

 


    </main>
    